"Here is your technical specification for **Quant**, 
based on the audit of the provided script and the requirements for enhanced analysis
 and visualization:\n\n---\n\n
 ##  **Technical Specification: Enhanced Email Position Analysis**\n\n### 
 **Analysis Goals**
 - **Temporal Trend Analysis**: Quantify how participant positions evolve across rounds (e.g., convergence/divergence, sentiment shifts).\n- **Participant Influence**: Identify participants whose positions consistently bridge or polarize clusters.\n- **Consensus Convergence**: Measure round-over-round agreement using Krippendorff’s alpha and Jaccard similarity.\n- **Topic Evolution**: Track topic prominence and transitions between rounds.\n- **Network Analysis**: Visualize idea clustering and participant interactions as a network graph.\n\n---\n\n### **Required Outputs**\n\n#### **1. Visualizations**\n- **Sankey Diagram of Position Flows**\n  - *Data Inputs*: `position_id`, `round_number`, `cluster` (from K-means)\n  - *Design Notes*: Use `matplotlib`/`seaborn`; color flows by cluster; annotate with participant IDs.\n- **Round-over-Round Sentiment Heatmap**\n  - *Data Inputs*: `round_number`, `sentiment` (from TextBlob)\n  - *Design Notes*: `seaborn.heatmap`; x-axis = rounds, y-axis = participants; color scale = sentiment polarity.\n- **Network Graph of Idea Clustering**\n  - *Data Inputs*: `position_id`, `cluster`, `round_number`\n  - *Design Notes*: Use `networkx`; nodes = positions, edges = similarity (TF-IDF cosine), color by cluster.\n- **Topic Prominence Bar Chart**\n  - *Data Inputs*: LDA topic distributions per round\n  - *Design Notes*: Stacked bar chart; x-axis = rounds, y-axis = topic weights.\n\n#### **2. Statistical Reports**\n- **Krippendorff’s Alpha for Inter-Participant Agreement**\n  - *Grouping*: By round, by participant role (if available in metadata).\n- **Jaccard Similarity Between Rounds**\n  - *Grouping*: Pairwise round comparisons.\n- **Cluster Stability Metrics**\n  - *Metric*: Silhouette score per round.\n\n---\n\n### **Data Preprocessing**\n- **Cleaning**:\n  - Handle missing `metadata` with mode imputation.\n  - Drop positions with `<3 words` (likely noise).\n- **Feature Engineering**:\n  - Add `position_similarity_score` (TF-IDF cosine similarity between all pairs).\n  - Add `round_number` and `participant_id` as categorical features for grouping.\n\n---\n\n### **Edge Cases**\n- If `<5 positions` in a round, flag as “low-confidence” in outputs and exclude from consensus metrics.\n- For network graph: if similarity matrix is sparse, use thresholding (e.g., only show edges with similarity > 0.3).\n\n---\n\n### **Code Snippets (Hints)**\n\n#### **Round-over-Round Jaccard Similarity**\n```python\nfrom sklearn.metrics import jaccard_score\n\ndef round_jaccard_similarity(round1_positions, round2_positions):\n    # Vectorize positions (e.g., TF-IDF)\n    # Compute Jaccard similarity between sets of top terms\n    return jaccard_score(...)\n```\n\n#### **Network Graph Construction**\n```python\nimport networkx as nx\n\ndef build_position_network(df):\n    G = nx.Graph()\n    for _, row in df.iterrows():\n        G.add_node(row['position_id'], cluster=row['cluster'])\n    # Add edges based on similarity_score\n    return G\n```\n\n#### **Krippendorff’s Alpha**\n```python\nimport krippendorff  # pip install krippendorff\n\ndef compute_alpha(df):\n    return krippendorff.alpha(\n        reliability_data=df[['participant_id', 'round_number', 'cluster']].values,\n        level_of_measurement='nominal'\n    )\n```\n\n---\n\n### **Validation Criteria**\n- **Data Integrity**: Assert all visualization data aggregates match raw CSV sums.\n- **Statistical Validity**: Krippendorff’s alpha > 0.6 for “reliable” rounds.\n- **Visualization Checks**: No overlapping nodes in network graph; Sankey flows sum to 100% per round.\n\n---\n\n**End of Spec**"
