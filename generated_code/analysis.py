#!/usr/bin/env python3
"""
Analysis code generated by Dev agent.
This file can be executed locally to generate visualizations.
"""

import os
import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
from sklearn.feature_extraction.text import TfidfVectorizer
from sklearn.cluster import KMeans
from scipy.stats import kruskal, mannwhitneyu
from textblob import TextBlob
from itertools import combinations
import logging
from nltk.corpus import stopwords
from nltk.stem import WordNetLemmatizer
from nltk.tokenize import word_tokenize
import nltk

# Set up logging
logging.basicConfig(level=logging.INFO, format='%(asctime)s - %(levelname)s - %(message)s')
logger = logging.getLogger(__name__)

# Load the data
csv_data = '''
position_id,participant,question,position_text,position_type,strength
adawson_q1a_p1,adawson,Q1a,"Client-side JS has become dominant since ES6+, shifting energy cost to users",core_position,strong
adawson_q1a_p2,adawson,Q1a,Devices SHOULD be considered but cannot be reliably modeled due to privacy/fingerprinting complexity,core_position,moderate
adawson_q1c_p1,adawson,Q1c,Tier 2: use reference values with embodied carbon from baseline devices averaged across market (Boavizta data),core_position,strong
adawson_q3_p1,adawson,Q3,"Option C: development may be outsourced/different department, measurement externally undertaken",core_position,moderate
adawson_q4_p1,adawson,Q4,Approach B: allow calculators to set own flags for caching as browser storage evolves,core_position,moderate
adawson_q6_p1,adawson,Q6,Approach B: don't assume sustainability claims unless tested and validated,core_position,strong
adawson_q6_p2,adawson,Q6,"Require industry proxy data with documented limitations, or conservative worst-case estimate",implementation_detail,strong
cadams_q1a_p1,cadams,Q1a,"Position A: devices must be included because browsing happens there, easier to measure on reference devices",core_position,strong
cadams_q1a_p2,cadams,Q1a,Small preset number of reference devices makes calculations simpler for embodied carbon,implementation_detail,strong
cadams_q1a_p3,cadams,Q1a,"Allow custom reference devices for products with very specific users, additional to common devices",nuance,moderate
cadams_q1c_p1,cadams,Q1c,Tier 3 better: specific device models as reference versions make things more credible and reproducible,core_position,strong
cadams_q1c_p2,cadams,Q1c,Draws attention to fact that most users have different setups than professional engineers with high-end equipment,nuance,moderate
cadams_q1c_p3,cadams,Q1c,Follows precedent of large organizations designing for low-end/older phones and PCs of modest spec,nuance,moderate
cadams_q1c_p4,cadams,Q1c,Echoes German Blue Angel Standard requiring software to run on ~5-year-old hardware,nuance,moderate
cadams_q2_p1,cadams,Q2,Position A: focusing on production avoids supply chain complexity of SaaS/open source in development,core_position,strong
cadams_q3_p1,cadams,Q3,Development has environmental footprint but implementing would be very difficult with supply chains,core_position,moderate
cadams_q3_p2,cadams,Q3,Recommend SCI for CI as separate standard to avoid muddying waters for web focus,dissenting,strong
cadams_q5_p1,cadams,Q5,Not convinced including server is good idea due to near-impossible independent reproduction (credibility/trust),dissenting,strong
cadams_q5_p2,cadams,Q5,Go for minimum server version allowing easy reproduction by auditor/second vendor,core_position,strong
cadams_q5_p3,cadams,Q5,More useful to have consistent testing system than precisely reproduce production conditions,core_position,moderate
cadams_q5_p4,cadams,Q5,"Need to simplify server-side similar to reference devices, otherwise reproduces SCI flexibility problems",core_position,moderate
cadams_q5_p5,cadams,Q5,Message queues/background workers: IN,implementation_detail,strong
cadams_q5_p6,cadams,Q5,First-party microservices: IN,implementation_detail,strong
cadams_q5_p7,cadams,Q5,Monitoring (operational): OUT,implementation_detail,strong
cadams_q5_p8,cadams,Q5,Monitoring (analytics/observability): OUT,implementation_detail,strong
cadams_q5_p9,cadams,Q5,Security infrastructure: OUT,implementation_detail,strong
cadams_q5_p10,cadams,Q5,Container orchestration: OUT,implementation_detail,strong
cadams_q6_p1,cadams,Q6,Approach D: mandate conservative worst-case estimate with documented limitations,core_position,strong
cadams_q6_p2,cadams,Q6,Don't make guesses based on execution time/payload - allows score based on disclosure levels,implementation_detail,moderate
cadams_q6_p3,cadams,Q6,Header disclosing SCI per server request makes scores look better with transparency,implementation_detail,moderate
cadams_q6_p4,cadams,Q6,Create scoring structure: zero disclosure / partial disclosure / full disclosure levels,implementation_detail,moderate
cadams_q7_p1,cadams,Q7,Easier to get process-level energy consumption figures now,nuance,moderate
cadams_q7_p2,cadams,Q7,Worst-case default creates incentive for transparency - better numbers require sharing data,core_position,strong
cadams_q9_p1,cadams,Q9,"Include server embodied proportional to time, with explicit assumptions about hardware lifespan",core_position,strong
cadams_q9_p2,cadams,Q9,"If lifespan longer than average, should be reflected as incentive to extend system life",implementation_detail,moderate
cadams_q10_p1,cadams,Q10,Server-centric vs end-user-device-centric viewpoints create fundamental tension,core_position,strong
cadams_q10_p2,cadams,Q10,SCI web focused on browsers is easy to measure and independently verify with reference devices/constants,dissenting,strong
cadams_q10_p3,cadams,Q10,"Servers make problem much harder, need different approach in separate standard composable with SCI Web",dissenting,strong
cadams_q10_p4,cadams,Q10,Large system boundaries include elements web app builders have no real prospect of influencing,dissenting,strong
cadams_q10_p5,cadams,Q10,Network consumption incredibly difficult to attribute to any one actor - better as constant showing where levers exist,dissenting,strong
cfassett_cons_p1,cfassett,Consensus,"Operational vs lifecycle is fundamental measurement coherence issue, not just preference",core_position,strong
cfassett_cons_p2,cfassett,Consensus,"Lifecycle camp intellectually wants to capture everything, but different activities need different measurement approaches",core_position,strong
cfassett_cons_p3,cfassett,Consensus,Cramming everything into one number gives muddy composite nobody knows how to improve,core_position,strong
cfassett_cons_p4,cfassett,Consensus,"Explicitly fork: SCI Web Operations (runtime only, for engineers) and SCI Web Lifecycle (comprehensive, for reporting)",dissenting,strong
cfassett_q1a_p1,cfassett,Q1a,Position A mandatory inclusion - arguments against are 'it's hard' not 'it's wrong',core_position,strong
cfassett_q1a_p2,cfassett,Q1a,Excluding devices like measuring car emissions without counting the engine,core_position,strong
cfassett_q1c_p1,cfassett,Q1c,No to tiered approach - flexibility makes standards less useful,dissenting,strong
cfassett_q1c_p2,cfassett,Q1c,Organizations will gravitate to whatever tier makes numbers look best,dissenting,strong
cfassett_q2_p1,cfassett,Q2,Position A operational only - development activities have fundamentally different optimization targets,core_position,strong
cfassett_q4_p1,cfassett,Q4,"Approach D: just measure actual data transferred, cache is implementation detail showing up in outcomes",core_position,strong
cfassett_q10_p1,cfassett,Q10,"Comparability is entire point of standard, not just nice-to-have",core_position,strong
cfassett_q10_p2,cfassett,Q10,Tiers destroy comparability - Org A Tier 1 0.5 vs Org B Tier 3 0.8 tells you nothing,dissenting,strong
cfassett_q10_p3,cfassett,Q10,Device inclusion debate conflates 'hard to measure precisely' with 'shouldn't measure at all',core_position,strong
cfassett_q10_p4,cfassett,Q10,"Accept imprecise measurements everywhere in software metrics, question is whether excluding devices makes metric meaningless (it does)",core_position,strong
cfassett_q10_p5,cfassett,Q10,Mixing operational and development breaks metric-to-emissions relationship: could improve SCI by running fewer tests while shipping less efficient code,dissenting,strong
dschein_q1a_p1,dschein,Q1a,Position C appropriate - embodied impacts very difficult to deal with if SCI targets developers,core_position,moderate
dschein_q1b_p1,dschein,Q1b,"Applications cannot directly affect embodied impacts - embodied arises during manufacturing, apps used afterwards",dissenting,strong
dschein_q1b_p2,dschein,Q1b,"If argument is future embodied impact affecting future purchase behavior, no convincing argument apps can affect purchase behavior",dissenting,strong
dschein_q1c_p1,dschein,Q1c,NO to tiered approach,dissenting,strong
dschein_q2_p1,dschein,Q2,Position A - everything else going to be difficult to express quantitatively,core_position,moderate
dschein_q3_p1,dschein,Q3,Quantitative approach in spirit of SCI impossible if fixed impacts brought into system boundaries,core_position,strong
dschein_q3_p2,dschein,Q3,Would like to hear how proponents for inclusive boundaries imagine consequential allocation,edge_case,moderate
dschein_q4_p1,dschein,Q4,Approach A: heuristic factors based on historical data,core_position,moderate
ffullone_cons_p1,ffullone,Consensus,Device inclusion framed as 'disagreement' understates case - non-negotiable for credibility,core_position,strong
ffullone_cons_p2,ffullone,Consensus,"Complexity concerns are implementation details addressable through tiered methodologies, not exclusion justification",core_position,strong
ffullone_cons_p3,ffullone,Consensus,Only Position A operational-only is methodologically sound - Position B creates unsolvable temporal allocation,core_position,strong
ffullone_cons_p4,ffullone,Consensus,Position C hides boundary problems behind measurement frequency without resolving them,dissenting,moderate
ffullone_cons_p5,ffullone,Consensus,Cache methodology: only heuristics and explicit scenarios provide replicable methodologies,core_position,moderate
ffullone_cons_p6,ffullone,Consensus,"Approach D confuses traffic volume with efficiency, Approach B offers no verification method",dissenting,moderate
ffullone_cons_p7,ffullone,Consensus,"Unaddressed: WebAssembly client computation allocation, Service Worker traffic interception, Progressive Enhancement",edge_case,moderate
ffullone_q1a_p1,ffullone,Q1a,Position A mandatory - shifting costs problem: server-rendered 50KB appears worse than 2MB SPA when SPA consumes 9× MORE total,core_position,strong
ffullone_q1a_p2,ffullone,Q1a,"If devices optional, incentivizes client-side processing to game backend metrics",core_position,strong
ffullone_q1a_p3,ffullone,Q1a,"Org A includes devices, B excludes = incomparable values, defeats standardization",core_position,strong
ffullone_q1a_p4,ffullone,Q1a,SCI for AI Consumer Boundary includes hardware for inference - same principle applies,nuance,strong
ffullone_q1a_p5,ffullone,Q1a,"Embodied allocation when shared: (Device_embodied / Lifetime_hours) × Usage_hours, conservative underestimate",implementation_detail,strong
ffullone_q1b_p1,ffullone,Q1b,Device data: User-Agent strings 80%+ coverage + categories for remainder,implementation_detail,strong
ffullone_q1b_p2,ffullone,Q1b,Model uncertainty: tiered simplified categories to device-specific,implementation_detail,moderate
ffullone_q1b_p3,ffullone,Q1b,Usage variability: measure application duration not total device uptime,implementation_detail,moderate
ffullone_q1b_p4,ffullone,Q1b,Reference accuracy: published LCA data + industry standards with disclosed sources,implementation_detail,moderate
ffullone_q1c_p1,ffullone,Q1c,"Oppose Tier 1 without embodied carbon - embodied ~40% device footprint, making optional creates permanence at low tier",dissenting,strong
ffullone_q1c_p2,ffullone,Q1c,"Counter-proposal: all tiers include embodied, vary only methodology sophistication",dissenting,strong
ffullone_q1c_p3,ffullone,Q1c,"Tier 1: categories with SWDM v4 values, allocation by reservation",implementation_detail,moderate
ffullone_q1c_p4,ffullone,Q1c,"Tier 2: User-Agent parsing, allocation by actual utilization",implementation_detail,moderate
ffullone_q1c_p5,ffullone,Q1c,"Tier 3: Real User Monitoring, device-specific data, fine-grained attribution",implementation_detail,moderate
ffullone_q1c_p6,ffullone,Q1c,Mixed-tier implementation acceptable with disclosure per component,nuance,moderate
ffullone_q2_p1,ffullone,Q2,Position A strongly support - SCI for AI precedent: Consumer (inference) separate from Provider (training),core_position,strong
ffullone_q2_p2,ffullone,Q2,"Separation rationale: different optimization targets, time scales, responsible parties",core_position,strong
ffullone_q2_p3,ffullone,Q2,"ISO/IEC 21031:2024 lists development as 'may be included' not 'must', supports separate-boundary",nuance,strong
ffullone_q2_p4,ffullone,Q2,"Position B OBJECT: development activities don't scale with functional unit, unsolvable temporal allocation",dissenting,strong
ffullone_q2_p5,ffullone,Q2,Example: per page view makes Sunday low traffic 5× worse SCI for identical efficiency,dissenting,strong
ffullone_q2_p6,ffullone,Q2,"Perverse incentives: delay security patches, reduce testing, monolithic deployments",dissenting,strong
ffullone_q2_p7,ffullone,Q2,"Unsolvable edge cases: staging traffic, A/B tests dual versions, failed deploys, scheduled jobs",edge_case,strong
ffullone_q2_p8,ffullone,Q2,No Position B proponent provided allocation methodology or edge case resolution,dissenting,moderate
ffullone_q2_p9,ffullone,Q2,Position C OBJECT: non-solution hiding boundary ambiguity behind measurement frequency,dissenting,moderate
ffullone_q2_p10,ffullone,Q2,Position C example: hourly window with build/deployment/serving can be interpreted 3 ways = incomparable,dissenting,moderate
ffullone_q3_p1,ffullone,Q3,Option B: separate Development Boundary following SCI for AI Provider boundary model,core_position,strong
ffullone_q3_p2,ffullone,Q3,"Independent reporting: SCI_operational for serving users, SCI_development for build/deploy (future spec)",implementation_detail,strong
ffullone_q3_p3,ffullone,Q3,Separate boundaries make both actionable for different stakeholders and optimization strategies,nuance,moderate
ffullone_q4_p1,ffullone,Q4,"Approach A heuristic factors with mandatory disclosure, allow Approach C as Tier 3",core_position,strong
ffullone_q4_p2,ffullone,Q4,Cache behavior is statistical varying by time/user/content/geography,core_position,moderate
ffullone_q4_p3,ffullone,Q4,Approach D confuses traffic volume with efficiency: 100 req at 90% cache vs 1000 at 50% appears 50× worse for identical efficiency,dissenting,strong
ffullone_q4_p4,ffullone,Q4,Approach B declares 'warm cache' without verification method (50% hit rate? 95%?),dissenting,moderate
ffullone_q4_p5,ffullone,Q4,Heuristic methodology: Cache_factor = 1 - (Hit_rate × Size_reduction) with disclosed sources,implementation_detail,strong
ffullone_q4_p6,ffullone,Q4,Tiered: industry benchmarks (T1) → historical analytics (T2) → scenario measurements (T3),implementation_detail,moderate
ffullone_q5_p1,ffullone,Q5,Support tightly-scoped metrics with explicit exclusions over broad boundaries with uncertain models,core_position,strong
ffullone_q5_p2,ffullone,Q5,Message queues/workers: IN conditional - if output reaches users in production,implementation_detail,strong
ffullone_q5_p3,ffullone,Q5,First-party microservices: IN mandatory - prevents boundary manipulation,implementation_detail,strong
ffullone_q5_p4,ffullone,Q5,"Operational monitoring: IN - health checks, auto-scaling, circuit breakers participate in delivery",implementation_detail,strong
ffullone_q5_p5,ffullone,Q5,"Analytics monitoring: OUT - log aggregation, APM, tracing observe without participating",implementation_detail,strong
ffullone_q5_p6,ffullone,Q5,"Security infrastructure: IN - in request path, DDoS mitigation allocated by legitimate traffic only",implementation_detail,moderate
ffullone_q5_p7,ffullone,Q5,Container orchestration: IN proportional - allocated by CPU/memory-hours,implementation_detail,moderate
ffullone_q5_p8,ffullone,Q5,"Preference hierarchy: direct measurement > high-reliability models (±10%) > disclosed exclusion, never ±50% uncertainty",core_position,strong
ffullone_q6_p1,ffullone,Q6,Strongly support Approach A: three-tier categorization Essential/Enhancement/Development,core_position,strong
ffullone_q6_p2,ffullone,Q6,"Category A Essential: removal → >50% functional units undeliverable, MUST include with proxy never simple exclusion",implementation_detail,strong
ffullone_q6_p3,ffullone,Q6,"Category B Enhancement: removal → deliverable but degraded, MAY include, client-side captured in SCI_web",implementation_detail,moderate
ffullone_q6_p4,ffullone,Q6,"Category C Development: for development/analytics not production, EXCLUDE, belong in Development Boundary",implementation_detail,moderate
ffullone_q6_p5,ffullone,Q6,"Exception: if Category C >100KB payload or >200ms execution, include client impact as technical debt penalty",nuance,moderate
ffullone_q6_p6,ffullone,Q6,"Categorization test: disable service, attempt functional unit delivery, apply classification",implementation_detail,moderate
ffullone_q6_p7,ffullone,Q6,"Reject alternatives: Approach B no prioritization, C circular 'significant impact', D vague 'simple estimation'",dissenting,moderate
ffullone_q7_p1,ffullone,Q7,Support Perspective A proportional allocation with tiered implementation,core_position,strong
ffullone_q7_p2,ffullone,Q7,"Tier 1 Reservation: Reserved/Total, no profiling required, conservative",implementation_detail,moderate
ffullone_q7_p3,ffullone,Q7,"Tier 2 Utilization: Query_time/Total or CPU_hours/Total, rewards efficiency",implementation_detail,moderate
ffullone_q7_p4,ffullone,Q7,"Tier 3 Fine-grained: (Operations × Cost) / Total_cost, per-request tracking",implementation_detail,moderate
ffullone_q7_p5,ffullone,Q7,Reject Perspective C: exclusion ignores 20-40% backend energy; 100% worst-case absurd (10 apps = 1000%); equal split unfair,dissenting,strong
ffullone_q7_p6,ffullone,Q7,Edge cases: bursty workloads allocate within observation window only with disclosed timing,edge_case,moderate
ffullone_q7_p7,ffullone,Q7,"Cascading dependencies use direct allocation only not transitive (App→Queue, not App→Queue→DB)",edge_case,moderate
ffullone_q9_p1,ffullone,Q9,Include server embodied carbon proportional to usage time,core_position,strong
ffullone_q9_p2,ffullone,Q9,"Methodology: (Server_embodied / Lifetime_hours) × Window_hours × Allocation_%, parallel to device allocation",implementation_detail,strong
ffullone_q9_p3,ffullone,Q9,PUE doesn't cover this: measures operational overhead not manufacturing emissions,core_position,strong
ffullone_q9_p4,ffullone,Q9,"PUE 1.2 vs 1.8 = different operational efficiency, identical embodied footprint",nuance,moderate
ffullone_q9_p5,ffullone,Q9,Embodied 10-50% total server footprint: high utilization (90% CPU) = 10-15%; low (20%) = 40-50%,nuance,strong
ffullone_q9_p6,ffullone,Q9,Optional embodied removes incentive to improve utilization,core_position,moderate
ffullone_q9_p7,ffullone,Q9,Tiered: cloud provider aggregates (T1) → instance-specific LCA (T2) → actual hardware tracking (T3),implementation_detail,moderate
ffullone_q9_p8,ffullone,Q9,"Reject optional/excluded: inconsistent with mandatory device embodied, enables underutilization hiding",dissenting,strong
ffullone_q10_p1,ffullone,Q10,Representation gap: device inclusion framed as 'area of disagreement' understates the case,core_position,moderate
ffullone_q10_p2,ffullone,Q10,Cache flexibility: multiple methodologies with disclosure reflect architectural diversity better than forced uniformity,nuance,moderate
ffullone_q10_p3,ffullone,Q10,Allocation disclosure criticality: '18% database allocation' meaningless without methodology disclosure,core_position,moderate
ffullone_q10_p4,ffullone,Q10,"Development lifecycle: no participant provided concrete allocation methodology, confirms practical unimplementability",dissenting,strong
ffullone_q10_p5,ffullone,Q10,Temporal optimization carbon-aware workload shifting: out of scope - optimization strategies not measurement methodologies,edge_case,moderate
ffullone_q10_p6,ffullone,Q10,Functional unit guidance: e-commerce holiday peak - per-session vs per-purchase? Need selection criteria framework,edge_case,strong
ffullone_q10_p7,ffullone,Q10,"Attribution vs consequential: clarify SCI uses attributional (allocate existing emissions), consequential out of scope",edge_case,moderate
ffullone_q10_p8,ffullone,Q10,Geographic/temporal boundaries: global apps by region? Peak vs off-peak? Defer to future,edge_case,moderate
ffullone_q10_p9,ffullone,Q10,"Measurement verification: auditability, third-party verification, dispute resolution - governance questions appropriately deferred",edge_case,moderate
nramachandra_q1a_p1,nramachandra,Q1a,Position A: devices must be included as critical component,core_position,strong
nramachandra_q1a_p2,nramachandra,Q1a,Research shows end-user devices contribute ~20% total carbon emissions for IT and digital services,nuance,strong
nramachandra_q1a_p3,nramachandra,Q1a,"Emissions vary by usage, device type, time app runs on device, LCA, device performance",nuance,moderate
nramachandra_q1c_p1,nramachandra,Q1c,Tier 2 better: including embodied carbon crucial for full lifecycle emissions,core_position,strong
nramachandra_q1c_p2,nramachandra,Q1c,Tier 2 aligns with comprehensive carbon accounting and prevents shifting costs to clients,nuance,moderate
nramachandra_q1c_p3,nramachandra,Q1c,Tier 2 strikes balance between simplicity and comprehensiveness,core_position,moderate
nramachandra_q1c_p4,nramachandra,Q1c,Proportional allocation with reference values enables equitable assessment across devices,implementation_detail,moderate
nramachandra_q1c_p5,nramachandra,Q1c,Tier 2 feasible for organizations without resources for complex Tier 3,nuance,moderate
nramachandra_q2_p1,nramachandra,Q2,Position B: provides holistic view allowing understanding of development practices impact on operational efficiency,core_position,strong
nramachandra_q2_p2,nramachandra,Q2,"Development, CI/CD, operational performance are interconnected, measuring all aspects helps identify bottlenecks",core_position,moderate
nramachandra_q2_p3,nramachandra,Q2,Aligns with DevOps and Agile frameworks - latest frameworks used today,nuance,moderate
nramachandra_q2_p4,nramachandra,Q2,Measuring throughout lifecycle allows catching issues early before they propagate to production,nuance,moderate
nramachandra_q2_p5,nramachandra,Q2,Ensures both development and operational needs met without compromising either front,nuance,moderate
nramachandra_q3_p1,nramachandra,Q3,Option C: not all organizations use same development infrastructure,core_position,strong
nramachandra_q3_p2,nramachandra,Q3,Conditional inclusion keeps SCI Web relevant and applicable to broader range of organizations,nuance,moderate
nramachandra_q3_p3,nramachandra,Q3,"Organizations not yet using certain practices not excluded from framework, encourages broader participation",nuance,moderate
nramachandra_q3_p4,nramachandra,Q3,Organizations feel empowered to explore new tools without mandatory compliance pressure,nuance,moderate
nramachandra_q3_p5,nramachandra,Q3,Organizations can provide feedback allowing SCI Web to evolve,nuance,moderate
nramachandra_q3_p6,nramachandra,Q3,Can analyze how development infra metrics impact performance for informed decision-making,nuance,moderate
nramachandra_q4_p1,nramachandra,Q4,Prefer multiple methodologies with disclosure requirements,core_position,strong
nramachandra_q4_p2,nramachandra,Q4,"Cache management complex, influenced by various factors - no one-size-fits-all solution",core_position,moderate
nramachandra_q4_p3,nramachandra,Q4,"Caching differs: e-commerce vs news sites, new vs returning users, React/Angular vs MPAs, cloud vs on-prem",nuance,strong
nramachandra_q6_p1,nramachandra,Q6,Approach C: include only services significantly impacting performance/sustainability,core_position,strong
nramachandra_q6_p2,nramachandra,Q6,"Ensures resources directed toward most relevant services, organizations focus on what matters",nuance,moderate
nramachandra_q6_p3,nramachandra,Q6,Simplifies compliance by avoiding categorizing every third-party service,nuance,moderate
nramachandra_q6_p4,nramachandra,Q6,When vendors don't provide data: use industry proxy data with documented limitations maintaining accountability,implementation_detail,strong
nramachandra_q7_p1,nramachandra,Q7,"Perspective A: proportional allocation based on usage metrics (CPU time, query execution, operation count)",core_position,strong
nramachandra_q7_p2,nramachandra,Q7,"Though data collection difficult, allocating on actual usage ensures accountability and promotes fairness",nuance,moderate
nramachandra_q7_p3,nramachandra,Q7,"Once SCI standardized and organizations in harmony, data collection won't be problem in shared environment",nuance,moderate
nramachandra_q9_p1,nramachandra,Q9,Include server embodied proportional to usage time,core_position,strong
nramachandra_q9_p2,nramachandra,Q9,"Standard should mention 'X' is server infra embodied, 'Y' is end-user device embodied",implementation_detail,moderate
nramachandra_q9_p3,nramachandra,Q9,PUE and cloud metrics don't capture embodied carbon from manufacturing/transportation/installation,core_position,strong
nramachandra_q9_p4,nramachandra,Q9,Relying solely on PUE leads to underestimation of overall carbon footprint,nuance,moderate
nramachandra_q9_p5,nramachandra,Q9,Excluding server embodied undermines sustainability efforts across entire infrastructure,dissenting,moderate
rpomado_q1a_p1,rpomado,Q1a,Position B or C: trying to achieve optimum at beginning of journey will lead to failure,core_position,moderate
rpomado_q1a_p2,rpomado,Q1a,Mandatory inclusion requires big effort with risk of overcomplication in new 'land',core_position,moderate
rpomado_q1b_p1,rpomado,Q1b,Uncertainty about which device models/categories to use,implementation_detail,moderate
rpomado_q1b_p2,rpomado,Q1b,Difficulty allocating embodied carbon when devices shared,implementation_detail,moderate
rpomado_q1b_p3,rpomado,Q1b,Variability in device usage patterns across users,implementation_detail,moderate
rpomado_q1c_p1,rpomado,Q1c,Tiered approach can simplify the model,core_position,moderate
rpomado_q2_p1,rpomado,Q2,"Position A: continuous measurement needed otherwise no sense, just big estimation",core_position,strong
rpomado_q2_p2,rpomado,Q2,"Need to balance estimation trying to be more accurate as possible, only continuous measurement can do it",core_position,moderate
rpomado_q3_p1,rpomado,Q3,Option B: development should be integrated in measurement as embodied emission,core_position,moderate
rpomado_q3_p2,rpomado,Q3,Software emitted carbon during dev phase (building phase),nuance,moderate
rpomado_q4_p1,rpomado,Q4,"Tiered approach gives power to start small and expand, flexibility to estimate when missing details",core_position,moderate
rpomado_q5_p1,rpomado,Q5,Shared services should be OPTIONAL for everyone as part of separated metric,core_position,moderate
rpomado_q5_p2,rpomado,Q5,Shared services more complex to estimate,nuance,moderate
rpomado_q6_p1,rpomado,Q6,Approach D best to avoid over complication,core_position,moderate
rpomado_q7_p1,rpomado,Q7,"Option B: clearly exclude allocation of shared emission but document impact, simplifies model",core_position,moderate
rpomado_q9_p1,rpomado,Q9,"Include embodied but keep separated, not included in variable carbon emission",core_position,moderate
rpomado_q9_p2,rpomado,Q9,More accurate but also keeps separated variable and fixed emission,nuance,moderate
rsholin_cons_p1,rsholin,Consensus,"HTTP/HTTPS + browser definition appropriate, comprehensive network/third-party inclusion supported",core_position,strong
rsholin_cons_p2,rsholin,Consensus,Distinguishing from passive content consumption disagree - passive generates lots of views/consumption/emissions,dissenting,moderate
rsholin_cons_p3,rsholin,Consensus,Networking/devices should use global defaults for things in no control of developer building web app,core_position,strong
rsholin_cons_p4,rsholin,Consensus,"Third-party services interesting - affect performance, but emissions are scope-three-ish from third-party not web app",nuance,moderate
rsholin_cons_p5,rsholin,Consensus,Anything optionally in scope is complicating - giving users choices in standard,dissenting,strong
rsholin_cons_p6,rsholin,Consensus,Optional things become guidelines not standard - either IN or OUT,dissenting,strong
rsholin_cons_p7,rsholin,Consensus,"If OUT, point to W3C sustainable web guidelines for best practices",implementation_detail,moderate
rsholin_cons_p8,rsholin,Cons ensus,"Development lifecycle activities are upstream emissions, scope-3-like",nuance,moderate
rsholin_cons_p9,rsholin,Consensus,Apply scope 1/2/3 carbon accounting rules about boundaries might be helpful,implementation_detail,moderate
rsholin_cons_p10,rsholin,Consensus,Monitoring/logging depends on whether part of application or third-party,nuance,moderate
rsholin_q1c_p1,rsholin,Q1c,"Tier 1 recommendation: simplified device categories with standard reference values, no embodied carbon",core_position,strong
rsholin_q1c_p2,rsholin,Q1c,Basic analytics can tell % visitors using mobile or desktop (don't separate laptop and desktop),implementation_detail,moderate
rsholin_q1c_p3,rsholin,Q1c,Standard emissions value and source for each could be included in specification,implementation_detail,moderate
rsholin_q2_p1,rsholin,Q2,Conflating two boundaries: 1) operational vs lifecycle different from 2) time period as denominator unit,core_position,strong
rsholin_q2_p2,rsholin,Q2,Time period should NOT be functional unit for SCI,core_position,strong
rsholin_q2_p3,rsholin,Q2,Correct functional unit might be 'per thousand pageviews' aligning with advertising CPM (cost per mille),core_position,strong
rsholin_q2_p4,rsholin,Q2,"Recommend Position B: complete lifecycle, but upstream development emissions use default constant not precise measurement",core_position,moderate
rsholin_q3_p1,rsholin,Q3,Option D: fully integrated into SCI Web measurements using standard upstream values,core_position,moderate
rsholin_q3_p2,rsholin,Q3,Use standard upstream values to reduce complexity and avoid requiring precise measurements,implementation_detail,moderate
rsholin_q4_p1,rsholin,Q4,"Approach D: measure actual data transferred, that's where emissions happening",core_position,strong
rsholin_q4_p2,rsholin,Q4,Do NOT measure 'avoided' emissions thanks to caching - measure actual emissions,core_position,strong
rsholin_q4_p3,rsholin,Q4,"One methodology for consistency and comparability, no matter caching/CDN approach",core_position,strong
rsholin_q4_p4,rsholin,Q4,W3C Sustainability Guidelines include best practices - SCI should measure results not every possible scenario,nuance,moderate
rsholin_q5_p1,rsholin,Q5,Message queues/background workers: OUT,implementation_detail,strong
rsholin_q5_p2,rsholin,Q5,First-party microservices: IN,implementation_detail,strong
rsholin_q5_p3,rsholin,Q5,Monitoring operational: OUT IF THIRD-PARTY,implementation_detail,strong
rsholin_q5_p4,rsholin,Q5,Monitoring analytics/observability: OUT IF THIRD-PARTY,implementation_detail,strong
rsholin_q5_p5,rsholin,Q5,Security infrastructure: OUT IF THIRD-PARTY,implementation_detail,strong
rsholin_q5_p6,rsholin,Q5,Container orchestration: OUT,implementation_detail,strong
rsholin_q5_p7,rsholin,Q5,SCI should capture first-party carbon under web developer's control,core_position,strong
rsholin_q5_p8,rsholin,Q5,If org builds/hosts own infra making first-party calls affecting energy: IN scope,implementation_detail,strong
rsholin_q5_p9,rsholin,Q5,If calls to third-parties affect performance but not additional energy where hosted: OUT scope,implementation_detail,strong
rsholin_q5_p10,rsholin,Q5,"Third-party services at most included with default values, no expectation of real-world measurement",implementation_detail,moderate
rsholin_q6_p1,rsholin,Q6,"Blend of Approach C and D: only include if affect energy consumption, use estimated/default constants not precise measurements",core_position,strong
rsholin_q6_p2,rsholin,Q6,Question whether default constants exist - prerequisite for standard requiring inclusion,edge_case,moderate
rsholin_q6_p3,rsholin,Q6,"Standard could call for most detailed data freely available, fallback to industry proxy at worst",implementation_detail,moderate
rsholin_q6_p4,rsholin,Q6,Similar to GHG Protocol Scope 2 updates in progress,nuance,moderate
rsholin_q7_p1,rsholin,Q7,Perspective A makes most sense: proportional allocation based on usage metrics,core_position,strong
rsholin_q7_p2,rsholin,Q7,"If app uses shared resource, portion needs to be included in measurements",core_position,moderate
rsholin_q7_p3,rsholin,Q7,Right unit harder to answer - 'appropriate usage metrics' challenging to harmonize across different shared resource types,edge_case,moderate
rsholin_q9_p1,rsholin,Q9,Include embodied with two major categories,core_position,strong
rsholin_q9_p2,rsholin,Q9,If hardware owned/operated by web app makers (on-prem/colocated): allocate portion of embodied carbon for shared upstream infra,implementation_detail,strong
rsholin_q9_p3,rsholin,Q9,If cloud providers: may already be represented in data they provide to customers,implementation_detail,moderate
rsholin_q10_p1,rsholin,Q10,Need external guide/example for what's generally in scope for calculating emissions of anything,dissenting,strong
rsholin_q10_p2,rsholin,Q10,Re-center scope discussion using existing PCF (Product Carbon Footprint) and LCA (Life Cycle Assessment) standards,dissenting,strong
rsholin_q10_p3,rsholin,Q10,Explicitly apply GHG Protocol Scope 1/2/3 framework to establish clearer boundaries,dissenting,strong
rsholin_q10_p4,rsholin,Q10,Reference GHG Protocol diagram for guidance on what's typically in scope,implementation_detail,moderate
'''

from io import StringIO

df = pd.read_csv(StringIO(csv_data))

# Data Validation & Preprocessing
def validate_and_preprocess(df):
    """
    Validate and preprocess the input DataFrame.
    - Drop rows with missing critical values.
    - Remove duplicates.
    """
    logger.info("Starting data validation and preprocessing...")

    # Drop rows missing critical values
    df_clean = df.dropna(subset=['participant', 'position_text']).copy()

    # Remove duplicates
    df_clean = df_clean.drop_duplicates(subset=['participant', 'position_text'])

    logger.info(f"Data after validation and preprocessing: {len(df_clean)} rows.")
    return df_clean

df_clean = validate_and_preprocess(df)

# Text Normalization
def normalize_text(text_series):
    """
    Normalize text: lowercase, remove stopwords, lemmatize.
    """
    # Download required NLTK data
    import ssl
    try:
        _create_unverified_https_context = ssl._create_unverified_context
    except AttributeError:
        pass
    else:
        ssl._create_default_https_context = _create_unverified_https_context

    nltk.download('punkt_tab', quiet=True)
    nltk.download('stopwords', quiet=True)
    nltk.download('wordnet', quiet=True)
    nltk.download('omw-1.4', quiet=True)

    lemmatizer = WordNetLemmatizer()
    stop_words = set(stopwords.words('english'))

    normalized_texts = []
    for text in text_series:
        tokens = word_tokenize(text.lower())
        filtered = [lemmatizer.lemmatize(w) for w in tokens if w.isalpha() and w not in stop_words]
        normalized_texts.append(' '.join(filtered))

    return normalized_texts

df_clean['normalized_text'] = normalize_text(df_clean['position_text'])

# Sentiment Analysis
def analyze_sentiment(text_series):
    """
    Analyze sentiment of text data using TextBlob.
    """
    sentiments = [TextBlob(text).sentiment.polarity for text in text_series]
    return sentiments

df_clean['sentiment_score'] = analyze_sentiment(df_clean['position_text'])

# Thematic Clustering
def perform_thematic_clustering(text_series, n_clusters=5):
    """
    Perform thematic clustering using TF-IDF and K-Means.
    """
    vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')
    tfidf_matrix = vectorizer.fit_transform(text_series)

    kmeans = KMeans(n_clusters=n_clusters, random_state=42)
    kmeans.fit(tfidf_matrix)
    clusters = kmeans.labels_

    # Get top terms per cluster
    terms = vectorizer.get_feature_names_out()
    cluster_terms = {}
    for i in range(n_clusters):
        idx = kmeans.labels_ == i
        cluster_terms[f'Cluster {i}'] = np.array(terms)[np.argsort(kmeans.cluster_centers_[i])[-10:]]

    return clusters, cluster_terms

clusters, cluster_terms = perform_thematic_clustering(df_clean['normalized_text'])

# Jaccard Similarity
def calculate_jaccard_similarity(clusters, text_series):
    """
    Calculate Jaccard similarity between rounds (questions) based on word sets.
    """
    # Create word sets for each question by combining all words from all texts in that question
    rounds = {}
    for question, group in df_clean.groupby('question'):
        # Combine all normalized texts for this question into one set of words
        all_words = set()
        for text in group['normalized_text']:
            all_words.update(text.split())
        rounds[question] = all_words

    # Calculate Jaccard similarity for each pair of questions
    round_pairs = list(combinations(rounds.keys(), 2))
    similarities = {}
    for i, j in round_pairs:
        intersection = len(rounds[i].intersection(rounds[j]))
        union = len(rounds[i].union(rounds[j]))
        jaccard = intersection / union if union > 0 else 0
        similarities[f"{i}_vs_{j}"] = jaccard

    return similarities

jaccard_similarities = calculate_jaccard_similarity(clusters, df_clean['normalized_text'])

# Sentiment Analysis
def perform_sentiment_analysis(df):
    """
    Perform statistical tests on sentiment scores across rounds.
    """
    round_groups = [group['sentiment_score'].values for name, group in df.groupby('question')]

    # Kruskal-Wallis test
    stat, p = kruskal(*round_groups)

    # Mann-Whitney U for pairwise comparisons
    pairwise_results = {}
    for i, j in combinations(df['question'].unique(), 2):
        stat, p = mannwhitneyu(
            df[df['question'] == i]['sentiment_score'],
            df[df['question'] == j]['sentiment_score'],
            alternative='two-sided'
        )
        pairwise_results[f"{i}_vs_{j}"] = {'statistic': stat, 'p-value': p}

    return {'kruskal': {'statistic': stat, 'p-value': p}, 'pairwise': pairwise_results}

sentiment_results = perform_sentiment_analysis(df_clean)

# Participant Consistency
def calculate_participant_consistency(df):
    """
    Calculate participant consistency using cosine similarity.
    """
    from sklearn.metrics.pairwise import cosine_similarity

    # Use TF-IDF vectors for each participant's positions
    vectorizer = TfidfVectorizer(max_df=0.95, min_df=2, stop_words='english')
    tfidf_matrix = vectorizer.fit_transform(df['normalized_text'])

    # Group by participant and average their TF-IDF vectors
    participant_vectors = {}
    for participant, group in df.groupby('participant'):
        participant_vectors[participant] = np.mean(
            tfidf_matrix[group.index].toarray(), axis=0
        )

    # Calculate cosine similarity for each participant across their positions
    consistency_scores = {}
    for participant, vec in participant_vectors.items():
        consistency_scores[participant] = cosine_similarity([vec], [vec])[0][0]

    return consistency_scores

consistency_scores = calculate_participant_consistency(df_clean)

# Visualizations
def plot_thematic_convergence(jaccard_similarities):
    """
    Plot thematic convergence as a heatmap.
    """
    questions = sorted(df_clean['question'].unique())
    n = len(questions)
    similarities_matrix = np.zeros((n, n))

    for i, q1 in enumerate(questions):
        for j, q2 in enumerate(questions):
            key = f"{q1}_vs_{q2}" if i < j else f"{q2}_vs_{q1}"
            similarities_matrix[i, j] = jaccard_similarities.get(key, 0)

    plt.figure(figsize=(10, 8))
    sns.heatmap(similarities_matrix, xticklabels=questions, yticklabels=questions, cmap='viridis', annot=True)
    plt.title('Thematic Convergence Across Questions (Jaccard Similarity)')
    plt.tight_layout()
    plt.savefig('thematic_convergence.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("Thematic convergence heatmap saved as 'thematic_convergence.png'")

plot_thematic_convergence(jaccard_similarities)

def plot_sentiment_trends(df):
    """
    Plot sentiment trends as a boxplot.
    """
    plt.figure(figsize=(12, 6))
    sns.boxplot(x='question', y='sentiment_score', data=df, palette='coolwarm')
    plt.title('Sentiment Trends Across Questions')
    plt.xticks(rotation=45)
    plt.tight_layout()
    plt.savefig('sentiment_trends.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("Sentiment trends boxplot saved as 'sentiment_trends.png'")

plot_sentiment_trends(df_clean)

def plot_participant_trajectories(df, consistency_scores):
    """
    Plot participant trajectories as a line plot.
    """
    plt.figure(figsize=(12, 6))
    for participant, group in df.groupby('participant'):
        plt.plot(group['question'], group['sentiment_score'], marker='o', label=participant, alpha=0.7)
    plt.title('Participant Sentiment Trajectories Across Questions')
    plt.xlabel('Question')
    plt.ylabel('Sentiment Score')
    plt.xticks(rotation=45)
    plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')
    plt.tight_layout()
    plt.savefig('participant_trajectories.png', dpi=300, bbox_inches='tight')
    plt.close()
    print("Participant trajectories line plot saved as 'participant_trajectories.png'")

plot_participant_trajectories(df_clean, consistency_scores)

# Print key results and metrics
print("\n=== Thematic Clustering Results ===")
for cluster, terms in cluster_terms.items():
    print(f"{cluster}: {', '.join(terms)}")

print("\n=== Jaccard Similarities ===")
for pair, similarity in jaccard_similarities.items():
    print(f"{pair}: {similarity:.3f}")

print("\n=== Sentiment Analysis Results ===")
print(f"Kruskal-Wallis test: statistic={sentiment_results['kruskal']['statistic']:.3f}, p-value={sentiment_results['kruskal']['p-value']:.3f}")
for pair, result in sentiment_results['pairwise'].items():
    print(f"{pair}: statistic={result['statistic']:.3f}, p-value={result['p-value']:.3f}")

print("\n=== Participant Consistency Scores ===")
for participant, score in consistency_scores.items():
    print(f"{participant}: {score:.3f}")

print("\n=== Summary Metrics ===")
print(f"Thematic convergence score (mean Jaccard similarity): {np.mean(list(jaccard_similarities.values())):.3f}")
print(f"Sentiment trend slope: {np.polyfit(range(len(df_clean['question'].unique())), [df_clean[df_clean['question'] == q]['sentiment_score'].mean() for q in sorted(df_clean['question'].unique())], 1)[0]:.3f}")